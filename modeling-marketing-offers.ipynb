{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6172ca-a487-4a96-818e-d9b01c595bf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install scipy\n",
    "#!pip install Jinja2\n",
    "#!pip install category-encoders\n",
    "#!pip install Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb24908c-2d85-44ad-a493-c2cffd7e80dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef\n",
    "from scipy.stats import mannwhitneyu\n",
    "import category_encoders as ce\n",
    "from boruta import BorutaPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493ed72e-b45d-4fb1-8b0d-8ff6e543f7b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Modeling logic**\n",
    "\n",
    "At first glance, the task appears to be about creating a dataset and training a predictive model such that, given a user profile and the characteristics of an offer, the model can estimate the probability that a transaction will occur. In other words, we want to model:\n",
    "\n",
    "**_P(Transaction ∣ User Profile,Offer)_**\n",
    "\n",
    "\n",
    "However, this is not sufficient for understanding the **true effectiveness of offers**. What we really care about is the **causal impact** of giving an offer, i.e., whether the offer actually changes user behavior compared to what they would have done without the offer.  \n",
    "\n",
    "This brings us to the concept of **uplift modeling**. Instead of just predicting the probability of a transaction under treatment (receiving the offer), we want to measure the **difference** between:  \n",
    "\n",
    "1. The probability that a transaction occurs if the user receives the offer.  \n",
    "2. The probability that a transaction occurs if the same user does **not** receive the offer.  \n",
    "\n",
    "The second probability depends only on the user’s intrinsic profile and past behavior (their “baseline” propensity to transact).  \n",
    "\n",
    "Formally, the **uplift** can be written as:\n",
    "\n",
    "**Uplift(x)=P(Transaction∣x,Offer) − P(Transaction∣x,No Offer)**\n",
    "\n",
    "Thus, the problem is not just predictive, but **causal**: we want to isolate the incremental effect of the offer on transactions. A positive uplift indicates that the offer increases the likelihood of a transaction, while a negative uplift means the offer may actually discourage transactions or simply attract users who would have transacted anyway (cannibalization).\n",
    "\n",
    "Here I first start with some data analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c908686f-dcb8-4569-8999-39c4c73ef359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Plan**:\n",
    "- Data Analysis for both datasets: **labeled_data_with_offer.csv** and **user_profiles_transaction_classes.csv**\n",
    "- Feature engineering if needed\n",
    "- Treating missing values\n",
    "- Categorized to numerical data convertion\n",
    "- Data split and modeling (take care of data leakage if any)\n",
    "- Metric choice (Recall, precision, AUC, AVG.precision)\n",
    "- scale_pos_weight setting if needed\n",
    "- Important feature analysis using Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900d6fdf-e8cf-4931-9a30-a9879ab1a2ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------Only to load from databricks volumes -------------------------------\n",
    "#user_files = glob.glob(\"/Volumes/workspace/default/data/user_profiles_transaction_classes.csv/part-*.csv\")\n",
    "#user_transaction_profile_df = pd.concat((pd.read_csv(f) for f in user_files), ignore_index=True)\n",
    "\n",
    "#offer_files = glob.glob(\"/Volumes/workspace/default/data/labeled_data_with_offer.csv/part-*.csv\")\n",
    "#offer_related_transaction_profile_df = pd.concat((pd.read_csv(f) for f in offer_files), ignore_index=True)\n",
    "\n",
    "#user_transaction_profile_df.to_csv(\"data/user_profiles_transaction_classes.csv\")\n",
    "#offer_related_transaction_profile_df.to_csv(\"data/offer_user_profiles_transaction_classes.csv\")\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "user_transaction_profile_df = pd.read_csv(\"data/processed/user_profiles_transaction_classes.csv\")\n",
    "offer_related_transaction_profile_df = pd.read_csv(\"data/processed/offer_user_profiles_transaction_classes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7b3c091-8083-4df8-bfbd-8d91ae06aa43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f9212f2-e57b-4950-b248-3a05e81b20df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### User profile <> Transaction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a352e9-40f7-495e-9f6b-1394398ff82e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_transaction_profile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa7507a6-679b-4281-8a2e-9da99422f7d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "offer_related_transaction_profile_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b40b4c9-7e38-4774-a630-2161d6d2e26c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "counts = (\n",
    "    user_transaction_profile_df\n",
    "    .groupby([\"gender\", \"class\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "counts[\"proportion\"] = counts.groupby(\"gender\")[\"count\"].transform(lambda x: x / x.sum())\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171671ad-3978-4249-bfc7-76f093e0c0d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_distribution_per_class(df, feature, class_name):\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for c in df[class_name].unique():\n",
    "        subset = df[df[class_name] == c]\n",
    "        plt.hist(\n",
    "            subset[feature].dropna(),\n",
    "            bins=30,\n",
    "            density=True,\n",
    "            alpha=0.5,\n",
    "            label=f\"Class {c}\"\n",
    "        )\n",
    "        \n",
    "        mean_val = subset[feature].mean()\n",
    "        plt.axvline(mean_val, color=\"blue\" if c==0 else \"red\", linestyle=\"--\", linewidth=1.5, label=f\"Mean (Class {c})\")\n",
    "        \n",
    "        median_val = subset[feature].median()\n",
    "        plt.axvline(median_val, color=\"blue\" if c==0 else \"red\", linestyle=\"-.\", linewidth=1.5, label=f\"Median (Class {c})\")\n",
    "\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Probability density of {feature} per Class\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a0ec9e-fc47-4279-8cd4-38f10d7d9cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(user_transaction_profile_df, \"credit_card_limit\",  \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f86c461b-f5a2-4635-b4b8-daa15b84b0e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group0 = user_transaction_profile_df.loc[user_transaction_profile_df[\"class\"] == 0, \"credit_card_limit\"].dropna()\n",
    "group1 = user_transaction_profile_df.loc[user_transaction_profile_df[\"class\"] == 1, \"credit_card_limit\"].dropna()\n",
    "\n",
    "print(\"Group0 size:\", len(group0))\n",
    "print(\"Group1 size:\", len(group1))\n",
    "print(\"Group0 unique values:\", group0.unique())\n",
    "print(\"Group1 unique values:\", group1.unique())\n",
    "print(\"Group0 dtypes:\", group0.dtype)\n",
    "print(\"Group1 dtypes:\", group1.dtype)\n",
    "print(\"Group0 has inf:\", np.isinf(group0).any())\n",
    "print(\"Group1 has inf:\", np.isinf(group1).any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc031a5a-1964-4c2f-8382-d33daa5e6abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " -->**This shows that the data are very likely manufactured data and are not real. Same values repeats over and over**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27500fe-1c13-4ae6-872a-955542d1892b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = mannwhitneyu(group0, group1, alternative=\"two-sided\")\n",
    "print(result.statistic, result.pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27903815-8246-4a1c-8e08-c05243732cc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--> **This p-value shows that the data rank for credit limit are infact different and statistically significant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a171712-6776-4026-9710-5be12bba193a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group0 = user_transaction_profile_df.loc[user_transaction_profile_df[\"class\"] == 0, \"age\"].dropna()\n",
    "group1 = user_transaction_profile_df.loc[user_transaction_profile_df[\"class\"] == 1, \"age\"].dropna()\n",
    "\n",
    "print(\"Group0 size:\", len(group0))\n",
    "print(\"Group1 size:\", len(group1))\n",
    "print(\"Group0 unique values:\", group0.unique())\n",
    "print(\"Group1 unique values:\", group1.unique())\n",
    "print(\"Group0 dtypes:\", group0.dtype)\n",
    "print(\"Group1 dtypes:\", group1.dtype)\n",
    "print(\"Group0 has inf:\", np.isinf(group0).any())\n",
    "print(\"Group1 has inf:\", np.isinf(group1).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8a916a-2824-4101-a3f6-76721980a466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(user_transaction_profile_df, \"age\",  \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ca513bd-0064-4bb2-97c0-efa4f983c9cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = mannwhitneyu(group0, group1, alternative=\"two-sided\")\n",
    "print(result.statistic, result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd415ad-6cff-4ab0-be64-b6b8deb3c633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--> **This p-value shows that the data rank for age are infact different and statistically significant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e60ac67b-3964-4338-b5bb-14a694650bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note: These features are very abnormal. Very high credit limits, people with age of 120. In real world these values dont make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc289343-d2dc-4592-957e-36f46833e664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lets evaluate the variable correlation here:\n",
    "corr = user_transaction_profile_df.drop([\"class\", \"registered_on\"], axis = 1).corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0eb1846-81a1-4b1d-86d4-6ee2ad74bdbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lets analyze the registration years as well. We want to answer: do people who registered earlier have a higher probability of having a transaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f456b8-fd64-433d-89ce-815c06d70fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_transaction_profile_df[\"registered_on\"] = pd.to_datetime(user_transaction_profile_df[\"registered_on\"], format=\"%Y%m%d\")\n",
    "user_transaction_profile_df[\"year\"] = user_transaction_profile_df[\"registered_on\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c23446fa-1e87-4f5f-a1d9-b207daff412f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(user_transaction_profile_df, \"year\", \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e4e174a-ad3f-4ba8-9fdc-21dfe90dc42c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is interesting because it shows that those erlier users are more faithful to the company than those who are newer and they buy more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acbb6c5f-fb90-40a2-9c81-2fc8a92ea639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### User profile <> Offer <> Transaction analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61a2243d-d178-43b7-b750-97780bf5b212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### User profile analysis per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b91b712-362c-4fe2-8002-c92602e59d73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "offer_related_transaction_profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f65c43d-a6ba-40b9-9a34-b0052c7eaac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(offer_related_transaction_profile_df, \"age\", \"offer_led_to_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "783e5364-5b13-49b5-8aa4-7c6208863467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group0 = offer_related_transaction_profile_df.loc[offer_related_transaction_profile_df[\"offer_led_to_transaction\"] == 0, \"age\"].dropna()\n",
    "group1 = offer_related_transaction_profile_df.loc[offer_related_transaction_profile_df[\"offer_led_to_transaction\"] == 1, \"age\"].dropna()\n",
    "\n",
    "print(\"Group0 size:\", len(group0))\n",
    "print(\"Group1 size:\", len(group1))\n",
    "print(\"Group0 unique values:\", group0.unique())\n",
    "print(\"Group1 unique values:\", group1.unique())\n",
    "print(\"Group0 dtypes:\", group0.dtype)\n",
    "print(\"Group1 dtypes:\", group1.dtype)\n",
    "print(\"Group0 has inf:\", np.isinf(group0).any())\n",
    "print(\"Group1 has inf:\", np.isinf(group1).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86cf9277-8419-48d0-a9d0-d85137cc9c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = mannwhitneyu(group0, group1, alternative=\"two-sided\")\n",
    "print(result.statistic, result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd953a6-e380-410f-890c-f5fdfb12d31d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(offer_related_transaction_profile_df, \"credit_card_limit\", \"offer_led_to_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "556228c9-145a-49a9-9880-eb9a0cae683d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here I want to know if there is a gender difference in the offer led to transaction\n",
    "gender_success_rate = (\n",
    "    offer_related_transaction_profile_df\n",
    "    .dropna(subset=[\"gender\"])\n",
    "    .groupby(\"gender\")[\"offer_led_to_transaction\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"success_rate\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    data=gender_success_rate,\n",
    "    x=\"gender\",\n",
    "    y=\"success_rate\"\n",
    ")\n",
    "plt.title(\"Proportion of Offers Leading to Transaction by Gender\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Proportion of Transactions (Success Rate)\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c795f313-fc52-457c-be84-319b14461209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There is no gender difference in accepting or not accepting an offer. Both genders used the offers more than not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139b9d9e-1948-472e-9af7-7a6d5b2882bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Analyzing the proportion of Offers Leading to Transaction by Offer Type\n",
    "offer_success_rate = (\n",
    "    offer_related_transaction_profile_df\n",
    "    .groupby(\"offer_type\")[\"offer_led_to_transaction\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"success_rate\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.barplot(\n",
    "    data=offer_success_rate,\n",
    "    x=\"offer_type\",\n",
    "    y=\"success_rate\",\n",
    "    palette=\"plasma\"\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2%}\",\n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=12, color=\"black\", weight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Proportion of Offers Leading to Transaction by Offer Type\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Offer Type\", fontsize=12)\n",
    "plt.ylabel(\"Success Rate\", fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(np.linspace(0,1,6), [f\"{x:.0%}\" for x in np.linspace(0,1,6)], fontsize=11)  # show % on y-axis\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68d1169a-2de7-4a5b-b5ed-c6fa1592f790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is interesting. The offers which have a discount or those of Buy One, Get One (BOGO) has higher conversion rate to a transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b27c46-1445-47f2-8e23-91ca53ce75c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(offer_related_transaction_profile_df, \"min_value\", \"offer_led_to_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "897b2cc6-2937-487f-92ad-f755f71733b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution_per_class(offer_related_transaction_profile_df, \"discount_value\", \"offer_led_to_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f62437-6d7c-4f02-8396-78271da281e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Analyzing the average Discount Value by Offer Led to Transaction\n",
    "discount_means = (\n",
    "    offer_related_transaction_profile_df\n",
    "    .groupby(\"offer_led_to_transaction\")[\"discount_value\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = sns.barplot(\n",
    "    data=discount_means,\n",
    "    x=\"offer_led_to_transaction\",\n",
    "    y=\"discount_value\",\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2f}\",\n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=12, color=\"black\", weight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Discount Value by Offer Led to Transaction\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Offer Led to Transaction\", fontsize=12)\n",
    "plt.ylabel(\"Average Discount Value\", fontsize=12)\n",
    "plt.xticks([0,1], [\"No (0)\", \"Yes (1)\"], fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ad83605-17ac-434c-b4db-48d2dd5b7891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Interstingly, those offers which led to transaction have higher vdiscount values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2921acf1-8394-4e4d-8ebe-64f2088ac980",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyzing which communication channel set has been more effective in marketing and offer campaign\n",
    "offer_success_rate = (\n",
    "    offer_related_transaction_profile_df\n",
    "    .groupby(\"channels\")[\"offer_led_to_transaction\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"success_rate\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.barplot(\n",
    "    data=offer_success_rate,\n",
    "    x=\"channels\",\n",
    "    y=\"success_rate\",\n",
    "    palette=\"plasma\"\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2%}\",\n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=12, color=\"black\", weight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Proportion of channel set Leading to Transaction by Offer Type\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Channels\", fontsize=12)\n",
    "plt.ylabel(\"Success Rate\", fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(fontsize=9)\n",
    "plt.yticks(np.linspace(0,1,6), [f\"{x:.0%}\" for x in np.linspace(0,1,6)], fontsize=11)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c354436-b6a9-4c95-964f-603a6f9beb8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Only web and mail are enough to grab users attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "218334e6-7527-4695-b5c2-7020c456ab0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyzing how the duration of the offer has affected the success rate\n",
    "discount_means = (\n",
    "    offer_related_transaction_profile_df\n",
    "    .groupby(\"offer_led_to_transaction\")[\"duration\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = sns.barplot(\n",
    "    data=discount_means,\n",
    "    x=\"offer_led_to_transaction\",\n",
    "    y=\"duration\",\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2f}\",\n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=12, color=\"black\", weight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Offer duration Led to Transaction\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Offer Led to Transaction\", fontsize=12)\n",
    "plt.ylabel(\"Average offer duration\", fontsize=12)\n",
    "plt.xticks([0,1], [\"No (0)\", \"Yes (1)\"], fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cdbee64-b846-4ac0-87f7-64797cbcf85c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Those offers that have higher duration more likely lead to a transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f788b848-c3c2-48f5-8025-e1dd5c5a3f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "corr = offer_related_transaction_profile_df.drop([\"offer_led_to_transaction\", \"offer_id\", \"account_id\", \"gender\", \"channels\", \"offer_type\", ], axis = 1).corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2d5104c-8e5c-40b8-9239-fc268954b5ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is mostly a good news because we do not have the risc of singularity and model unstability. For trees, we dont have the effect of biased featurte importance, or redundant random splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f989c73-fd81-4539-9491-bc8f815ad066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56bc4909-c060-4af8-8f35-25cea291db94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I will train two models, one for offer-userprofile transaction probability and the other one which accounts for no-offer probability using the user profile characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "099758d8-3512-4f10-a50f-96f35a5c17ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## I will keep the X_holdout and y_holdout for my final uplift test\n",
    "\n",
    "y = offer_related_transaction_profile_df[\"offer_led_to_transaction\"]\n",
    "X = offer_related_transaction_profile_df.drop(columns=[\"offer_led_to_transaction\", \"offer_id\", \"account_id\"])\n",
    "\n",
    "## ---- separating a test dataset for uplift calculation -----------------\n",
    "\n",
    "X_train_full, X_holdout, y_train_full, y_holdout = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "## -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ef1c444-7f8b-4b3e-b081-7470a76adea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Offer - transaction `predictor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bbf333b-1da3-4533-a8c3-7a750465538b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Categorical to numeric data conversion**\n",
    "\n",
    "Here I have several choices:\n",
    "1. Simple category to number conversion\n",
    "  * **Pros**: simple\n",
    "  * **Cons**: the numbers have no meaning at all, and no order exist.\n",
    "\n",
    "2. one-hot encoding\n",
    "  * **Pros**: preserves information about categories \n",
    "  * **Cons**: a) adds high dimensionality to the data; b) makes data sparse; c) when used with trees, it cause the tree to grow in the direction of zeros, to split redundantly, and to overfit due to tree complexity.\n",
    "\n",
    "3. using target-encoding\n",
    "  * **Pros**: when there is a strong relation between categories and the target, it helps the model to learn better and faster.\n",
    "  * **Cons**: Data leackage: if not handled correctly, it might leak target information and overestimate the model performance.\n",
    "\n",
    "  I will choose target-encoding due to the analysis results I had earlier that shows some categories are infact related to a specific target. For features like gender no encoding type will help due to the lack of correlation with the target.\n",
    "\n",
    "\n",
    "  **Algorithm selection**\n",
    "  - I chose a boosting algorithm called **Tree Xgboost**. It is an evolution of the Gradient Boosting algorithm which offers some benefits in addition to all the ensemble and error correction abilities of boosting methods:\n",
    "    - It uses Quantile-based Candidate Splits which improves the training time (it borrowed this feature from histogram binning of the LightGBM).\n",
    "    - Sparcity-aware-split-finding which enables the Xgboost to handle NaN values natively.\n",
    "    - Parallel Learning\n",
    "  \n",
    "  **Cross-validation**\n",
    "  - I used Stratified-k-fold due to its ability to create stratified folds which is more suitable for imbalanced classes. I could have also used Repeated class-wise stratified K-Fold in order to shuffle more and have a more realistic and rebust estimation\n",
    "\n",
    "  **No probability callibration**\n",
    "  - No probability callibration needed due to binary logistic loss (log loss).\n",
    "\n",
    "  **k-fold where k=5**\n",
    "   - The higher k, the lower the bias and higher the variance. Also the lower k, the higher model bias and higher the variance. This depends on the data size. Generally a k=10 or 5 is more common to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ba6340-a193-40e5-b204-07d57794d65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test(X, y, categorical_cols, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost classifier with stratified 5-fold CV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable (binary)\n",
    "    categorical_cols : list\n",
    "        List of categorical column names to be target-encoded\n",
    "    threshold : float\n",
    "        Classification threshold (default 0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    avg_precision, precisions, recalls, f1s, aucs, tprs, pr_aucs, mccs  = [], [], [], [], [], [], [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train_kfold, X_test_kfold = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "        y_train_kfold, y_test_kfold = y.iloc[train_index], y.iloc[test_index]\n",
    "        neg, pos = np.bincount(y_train_kfold)\n",
    "        scale_pos_weight_param = neg/pos\n",
    "\n",
    "        print(f\"\\nFold {fold+1}:\")\n",
    "        print(f\"  Train set class distribution: {np.bincount(y_train_kfold)}\")\n",
    "        print(f\"  Test set class distribution: {np.bincount(y_test_kfold)}\")\n",
    "\n",
    "        # Target encoding (fit only on training fold) so that I can avoid target leackage\n",
    "        target_encoder = ce.TargetEncoder(cols=categorical_cols)\n",
    "        X_train_enc = target_encoder.fit_transform(X_train_kfold, y_train_kfold)\n",
    "        X_test_enc = target_encoder.transform(X_test_kfold)\n",
    "\n",
    "\n",
    "        ## I will use binary logistic because it is naturally callibrated loss\n",
    "        model = XGBClassifier(\n",
    "            random_state=42,\n",
    "            eval_metric=\"logloss\",\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=1,\n",
    "            max_depth=4,\n",
    "            n_estimators=200,\n",
    "            scale_pos_weight = scale_pos_weight_param\n",
    "        )\n",
    "        model.fit(X_train_enc, y_train_kfold)\n",
    "\n",
    "        \n",
    "        y_pred_proba = model.predict_proba(X_test_enc)[:, 1]\n",
    "        y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "        precisions.append(precision_score(y_test_kfold, y_pred))\n",
    "        recalls.append(recall_score(y_test_kfold, y_pred))\n",
    "        f1s.append(f1_score(y_test_kfold, y_pred))\n",
    "        mccs.append(matthews_corrcoef(y_test_kfold, y_pred))\n",
    "        avg_precision.append(average_precision_score(y_test_kfold, y_pred_proba))\n",
    "        auc = roc_auc_score(y_test_kfold, y_pred_proba)\n",
    "        aucs.append(auc)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test_kfold, y_pred_proba)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        prec, rec, _ = precision_recall_curve(y_test_kfold, y_pred_proba)\n",
    "        pr_auc = average_precision_score(y_test_kfold, y_pred_proba)\n",
    "        pr_aucs.append(pr_auc)\n",
    "\n",
    "        precisions_interp.append(np.interp(mean_recall, rec[::-1], prec[::-1])) \n",
    "\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for i, tpr in enumerate(tprs):\n",
    "        plt.plot(mean_fpr, tpr, alpha=0.3, label=f\"Fold {i+1}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.plot(mean_fpr, np.mean(tprs, axis=0), color=\"b\", lw=2,\n",
    "            label=f\"Mean ROC (AUC={np.mean(aucs):.3f})\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Cross-Validated AUC-ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for i, prec in enumerate(precisions_interp):\n",
    "        plt.plot(mean_recall, prec, alpha=0.3, label=f\"Fold {i+1}\")\n",
    "    plt.plot(mean_recall, np.mean(precisions_interp, axis=0), color=\"r\", lw=2,\n",
    "            label=f\"Mean PR (AP={np.mean(pr_aucs):.3f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Cross-Validated Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Average ROC AUC:\", np.mean(aucs))\n",
    "    print(\"Average PR AUC:\", np.mean(pr_aucs))\n",
    "    print(\"Average precision:\", np.mean(precisions))\n",
    "    print(\"Average recall:\", np.mean(recalls))\n",
    "    print(\"Average f1:\", np.mean(f1s))\n",
    "    print(\"Mathews Correlation Coefficient (MCC):\", np.mean(mccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c24b14-8dd7-4490-a078-8425f83267ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_and_test(X_train_full, y_train_full, [\"gender\", \"channels\", \"offer_type\"], threshold= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8693956c-2150-4741-8a28-41877ff952d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here I am using Boruta as it is an improved version of feature permutation importance approach. It is not the same but has a similar idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89bc850d-a97b-4b5e-8bf5-295f2e4f0c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Feature importance using Boruta.\n",
    "def boruta_feature_importance(X: pd.DataFrame, y: pd.Series, max_iter: int = 100, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Run Boruta for feature importance and plot results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable (binary/multi-class)\n",
    "    max_iter : int\n",
    "        Maximum number of iterations for Boruta\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    feature_ranks : pd.DataFrame\n",
    "        DataFrame with features and their Boruta ranks\n",
    "    \"\"\"\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    boruta = BorutaPy(rf, n_estimators=\"auto\", verbose=0, random_state=random_state, max_iter=max_iter)\n",
    "    \n",
    "    boruta.fit(X.values, y.values)\n",
    "    \n",
    "    feature_ranks = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"rank\": boruta.ranking_,\n",
    "        \"support\": boruta.support_,\n",
    "        \"tentative\": boruta.support_weak_\n",
    "    }).sort_values(by=\"rank\")\n",
    "    \n",
    "    def categorize(row):\n",
    "        if row[\"support\"]:\n",
    "            return \"Strong\"\n",
    "        elif row[\"tentative\"]:\n",
    "            return \"Tentative\"\n",
    "        else:\n",
    "            return \"Weak\"\n",
    "    \n",
    "    feature_ranks[\"category\"] = feature_ranks.apply(categorize, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(\n",
    "        data=feature_ranks,\n",
    "        x=\"rank\", y=\"feature\", hue=\"category\",\n",
    "        dodge=False, palette={\"Strong\":\"green\", \"Weak\":\"red\", \"Tentative\":\"orange\"}\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Boruta Feature Importance (Strong, Weak, Tentative)\", fontsize=14, weight=\"bold\")\n",
    "    plt.xlabel(\"Boruta Rank (1 = Most Important)\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.legend(title=\"Feature Category\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14786d54-d715-42b3-840e-f33a58365a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\"gender\", \"offer_type\", \"channels\"]\n",
    "target_encoder = ce.TargetEncoder(cols=categorical_cols)\n",
    "X_train_enc = target_encoder.fit_transform(X_train_full, y_train_full)\n",
    "X_train_enc_clean = X_train_enc.dropna()\n",
    "y_train_enc_clean = y_train_full.loc[X_train_enc_clean.index]\n",
    "\n",
    "boruta_feature_importance(X_train_enc_clean, y_train_enc_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3a94cc2-bea4-4208-9315-f7f894531991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Profile - transaction `predictor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "937704f9-cdc0-447d-aee7-2478900deae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_transaction_profile_df[\"registered_on\"] = pd.to_datetime(user_transaction_profile_df[\"registered_on\"], format=\"%Y%m%d\")\n",
    "user_transaction_profile_df[\"year\"] = user_transaction_profile_df[\"registered_on\"].dt.year\n",
    "\n",
    "user_transaction_profile_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb5840b7-7bcb-4c70-8ad0-6d4c23c88ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = user_transaction_profile_df.drop([\"account_id\", \"registered_on\", 'class'], axis = 1)\n",
    "y = user_transaction_profile_df['class']\n",
    "train_and_test(X, y, [\"gender\"], threshold = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4756f09e-183b-4f86-bffe-3a473c32d9de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(cols=[\"gender\"])\n",
    "X_train_enc = target_encoder.fit_transform(X, y)\n",
    "X_train_enc_clean = X_train_enc.dropna()\n",
    "y_train_enc_clean = y.loc[X_train_enc_clean.index]\n",
    "\n",
    "boruta_feature_importance(X_train_enc_clean, y_train_enc_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "286a3bce-1ed3-4487-a0d4-f1e6bf955734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Risks and shortcomming in the current modeling strategy:**\n",
    "* Possible dataleackage due to sasonal patterns: the reaction to an offer or general tendency to buy can change depending on the month, day of month or economical situations of the region. Due to the lack of the transaction date and user profile region, some future information may have been leacked to the train data. The correct way to do this in this problem would be to separate the the test data in a temporal manner, and using only the future data in the test set.\n",
    "* The current model could be improved by hyperparameter tuning (using Random Rearch or Baysian tuning) but I didnt proceed with this step due to the lack of the time.\n",
    "* Use of the boosting algorithm can make the model worst if there is a significant proportion of data that are outliers. Boosting puts more weight on misclassified points. If those misclassifications are actually due to noise or mislabeled data, the model wastes capacity and degrades performance.\n",
    "* Like any other tree method, it can not extrapolate beyound the training data. This is crucial when there are complex patterns in data related to offer-to-transaction classes.\n",
    "* The size of the uplift model is very small and therefore I think it is not reliable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f73e500-a8f8-4abb-9fe3-f2b526ae1dbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model impact on holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2ee4dee-8218-4790-8628-04e3822155b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First lets train the model and generate the results with the model and create a cost comparison compared to naive way of sending offers to everyone.\n",
    "neg, pos = np.bincount(y_train_full)\n",
    "scale_pos_weight_param = neg/pos\n",
    "\n",
    "categorical_cols = [\"gender\", \"offer_type\", \"channels\"]\n",
    "target_encoder = ce.TargetEncoder(cols=categorical_cols)\n",
    "X_train_enc = target_encoder.fit_transform(X_train_full.drop('Unnamed: 0', axis = 1), y_train_full)\n",
    "\n",
    "model = XGBClassifier(\n",
    "            random_state=42,\n",
    "            eval_metric=\"logloss\",\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=1,\n",
    "            max_depth=4,\n",
    "            n_estimators=200,\n",
    "            scale_pos_weight = scale_pos_weight_param\n",
    "        )\n",
    "model.fit(X_train_enc, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d19707f1-377a-406d-b8bf-d33dc242538c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_holdout = X_holdout.drop('Unnamed: 0', axis = 1)\n",
    "X_holdout_transformed = target_encoder.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c41007d7-560b-4622-b5ff-ef62812d7f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_holdout_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b074992-4aee-4348-a4fa-127119599e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baseline_conversion_rate = y_holdout.mean()\n",
    "\n",
    "true_positives = np.sum((predictions == 1) & (y_holdout == 1))\n",
    "predicted_positives = np.sum(predictions == 1)\n",
    "\n",
    "model_conversion_rate = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "\n",
    "total_users = len(y_holdout)\n",
    "saved_offers = total_users - predicted_positives\n",
    "\n",
    "cost_per_offer = 0.05  \n",
    "savings = saved_offers * cost_per_offer\n",
    "\n",
    "print(f\"Baseline conversion rate (everyone targeted): {baseline_conversion_rate:.2%}\")\n",
    "print(f\"Model conversion rate (targeted): {model_conversion_rate:.2%}\")\n",
    "print(f\"Total users: {total_users}\")\n",
    "print(f\"Predicted positives (offers sent): {predicted_positives}\")\n",
    "print(f\"True positives captured: {true_positives}\")\n",
    "print(f\"Saved offers: {saved_offers} → Estimated savings = ${savings:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de673224-f3c7-4d1e-a09f-27dfc8cad491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This shows that if we had a set of users whose buying tendency was unknown to us, this model would help us not to send an offer to arround 5020 individuals. Here I used a threshold of 0.5 as my default threshold. The extent to which we would increase or decrease this threshold depends on our marketing goals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f70ebad-6d2d-4e46-ab58-181662a3cd99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Custo de envio de um SMS: 10 centavos\n",
    "\n",
    "Custo de envio de um email: 0.4 centavos\n",
    "\n",
    "Nesses 12658 usuários, a gente teria economizado cerca de **R$522** reais\n",
    "\n",
    "Ifood tem 55 milhões de clientes. Vamos pensar que 1MM desses usuários fossem escolhidos de forma aleatória e que a companhia enviasse email e SMS para todos esses usuários sem usar nenhum modelo.\n",
    "\n",
    "1000,000×5,249/12,658 ​≈ **414678.000** envios poupados\n",
    "\n",
    "Economia de 414678.000 * R$0.1 + 414678.000 * R$0.004 = **R$43.126** economizado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41fbdcf8-da18-4d94-a241-fc55bee781d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Uplifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "484b47ca-9718-47ea-bf17-a986fa1991b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_profile_cols = [\"age\", \"credit_card_limit\", \"registered_on\"]\n",
    "\n",
    "categorical_cols_profile = [\"gender\"]\n",
    "X = user_transaction_profile_df.drop([\"account_id\", \"registered_on\", 'class', 'Unnamed: 0', 'year'], axis = 1)\n",
    "y = user_transaction_profile_df['class']\n",
    "neg, pos = np.bincount(y)\n",
    "scale_pos_weight_param_profile = neg/pos\n",
    "\n",
    "target_encoder = ce.TargetEncoder(cols=categorical_cols_profile)\n",
    "X_train_enc_profile = target_encoder.fit_transform(X, y)\n",
    "\n",
    "user_transaction_model = XGBClassifier(\n",
    "            random_state=42,\n",
    "            eval_metric=\"logloss\",\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=1,\n",
    "            max_depth=4,\n",
    "            n_estimators=200,\n",
    "            scale_pos_weight = scale_pos_weight_param_profile\n",
    ")\n",
    "user_transaction_model.fit(X_train_enc_profile, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e0a2d03-5dff-4852-aa8c-fb7081c6d757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_holdout_uplift_test = X_holdout[X_train_enc_profile.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf217a7-5b55-4d20-8393-ea95b6f4adef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_holdout_uplift_test = target_encoder.transform(X_holdout_uplift_test)\n",
    "predictions_profile_only_model = user_transaction_model.predict(X_holdout_uplift_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b88a6f8a-e27a-41c9-ae3a-27fca9b72699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Uplift calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcfed4a2-3161-4a46-9417-f27ea7b2d384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uplift_df = pd.DataFrame({\n",
    "    \"p_with_offer\": predictions,\n",
    "    \"p_without_offer\": predictions_profile_only_model,\n",
    "})\n",
    "\n",
    "uplift_df[\"uplift\"] = uplift_df[\"p_with_offer\"] - uplift_df[\"p_without_offer\"]\n",
    "\n",
    "avg_uplift = uplift_df[\"uplift\"].mean()\n",
    "\n",
    "print(f\"Average uplift (overall effect of sending offers): {avg_uplift:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8872be1e-333d-4d4a-b285-20aa62584d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This shows that sending offer on average increases the transaction probability by **8.3%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "428e55f9-dd50-47ab-a150-3dd9b04f4f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### The impact  of the model on choosing the offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0d4fd26-1c0a-4ddb-b4ea-a2e0ba27d3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here, I will take instances from the hold out dataset and shuffle only the offer features and see how the model True Positives change. This shows the value that the model can bring compared to the baseline approach when the company randomly sends the offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "848c81f6-0bdf-4fb0-bfc2-c55e5a311dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_holdout_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a68a6e6-f2d0-4a19-a612-ca1317132069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_holdout_transformed_shuffled = X_holdout_transformed.copy()\n",
    "columns_to_shuffle = ['channels', 'discount_value', 'duration', 'min_value', 'offer_type']\n",
    "for column in columns_to_shuffle:\n",
    "    X_holdout_transformed_shuffled[column] = X_holdout_transformed_shuffled[column].sample(frac=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14501072-afa4-4045-91b0-dbf3c3f581f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "suffled_offers_predictions = model.predict(X_holdout_transformed_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59babe8f-3110-4e04-a252-d9c805f48ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predicted_positives = np.sum((suffled_offers_predictions == 1) & (y_holdout == 1))\n",
    "conversion_rate_for_random_offers = predicted_positives / np.sum(y_holdout == 1) if predicted_positives > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73a418ee-806b-4aaa-8b90-2854db390c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Conversion rate when the company sent random offers: {conversion_rate_for_random_offers:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be25818-cd2f-4daf-8a09-af465c51b600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"age\": [55, 72, 49, 118, 79],\n",
    "    \"credit_card_limit\": [63000, 96000, 60000, None, 113000],\n",
    "    \"gender\": [0.82, 0.83, 0.82, 0.76, 0.82],\n",
    "    \"registered_on\": [20151013, 20160503, 20151025, 20160926, 20160706],\n",
    "    \"channels\": [\"web,email,mobile\", \"web,mobile\", \"mobile,email\", \"web\", \"email\"],\n",
    "    \"discount_value\": [10, 5, 5, 5, 5],\n",
    "    \"duration\": [7, 7, 10, 7, 7],\n",
    "    \"min_value\": [10, 5, 20, 5, 5],\n",
    "    \"offer_type\": [\"informational\", \"bogo\", \"Discount\", \"informational\", \"bogo\"]\n",
    "})\n",
    "\n",
    "cols_to_shuffle = [\"channels\", \"discount_value\", \"duration\", \"min_value\", \"offer_type\"]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(5):  # create 5 shuffle states\n",
    "    temp = df.copy()\n",
    "    # Shuffle only selected columns\n",
    "    for col in cols_to_shuffle:\n",
    "        temp[col] = np.random.permutation(temp[col].values.copy())\n",
    "    \n",
    "    # Plot table for visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.axis(\"off\")\n",
    "    ax.axis(\"tight\")\n",
    "    ax.table(cellText=temp.values, colLabels=temp.columns, loc=\"center\", cellLoc='center')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save frame as image\n",
    "    fname = f\"imgs/frame_{i}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.close(fig)\n",
    "    frames.append(imageio.imread(fname))\n",
    "\n",
    "# Save as GIF\n",
    "imageio.mimsave(\"imgs/shuffle_demo.gif\", frames, duration=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43c70d3b-5be6-4cb4-a12f-5942391bbae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "modeling-marketing-offers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
